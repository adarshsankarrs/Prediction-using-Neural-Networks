{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7abd747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02c510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccace4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccaca6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \"Data/fruits/fruits-360/Training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path of the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac13d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = \"Data/fruits/fruits-360/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7452591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing directories present in the test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417983d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9351e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = os.listdir(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "408ed7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Class:  81\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Class: \", len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a1802bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Class:  81\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Class: \", len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc5479df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple Braeburn', 'Apple Golden 1', 'Apple Golden 2', 'Apple Golden 3', 'Apple Granny Smith', 'Apple Red 1', 'Apple Red 2', 'Apple Red 3', 'Apple Red Delicious', 'Apple Red Yellow', 'Apricot', 'Avocado', 'Avocado ripe', 'Banana', 'Banana Red', 'Cactus fruit', 'Cantaloupe 1', 'Cantaloupe 2', 'Carambula', 'Cherry 1', 'Cherry 2', 'Cherry Rainier', 'Cherry Wax Black', 'Cherry Wax Red', 'Cherry Wax Yellow', 'Clementine', 'Cocos', 'Dates', 'Granadilla', 'Grape Pink', 'Grape White', 'Grape White 2', 'Grapefruit Pink', 'Grapefruit White', 'Guava', 'Huckleberry', 'Kaki', 'Kiwi', 'Kumquats', 'Lemon', 'Lemon Meyer', 'Limes', 'Lychee', 'Mandarine', 'Mango', 'Maracuja', 'Melon Piel de Sapo', 'Mulberry', 'Nectarine', 'Orange', 'Papaya', 'Passion Fruit', 'Peach', 'Peach Flat', 'Pear', 'Pear Abate', 'Pear Monster', 'Pear Williams', 'Pepino', 'Physalis', 'Physalis with Husk', 'Pineapple', 'Pineapple Mini', 'Pitahaya Red', 'Plum', 'Pomegranate', 'Quince', 'Rambutan', 'Raspberry', 'Salak', 'Strawberry', 'Strawberry Wedge', 'Tamarillo', 'Tangelo', 'Tomato 1', 'Tomato 2', 'Tomato 3', 'Tomato 4', 'Tomato Cherry Red', 'Tomato Maroon', 'Walnut']\n"
     ]
    }
   ],
   "source": [
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f1f7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = os.listdir(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7d5a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple Braeburn', 'Apple Golden 1', 'Apple Golden 2', 'Apple Golden 3', 'Apple Granny Smith', 'Apple Red 1', 'Apple Red 2', 'Apple Red 3', 'Apple Red Delicious', 'Apple Red Yellow', 'Apricot', 'Avocado', 'Avocado ripe', 'Banana', 'Banana Red', 'Cactus fruit', 'Cantaloupe 1', 'Cantaloupe 2', 'Carambula', 'Cherry 1', 'Cherry 2', 'Cherry Rainier', 'Cherry Wax Black', 'Cherry Wax Red', 'Cherry Wax Yellow', 'Clementine', 'Cocos', 'Dates', 'Granadilla', 'Grape Pink', 'Grape White', 'Grape White 2', 'Grapefruit Pink', 'Grapefruit White', 'Guava', 'Huckleberry', 'Kaki', 'Kiwi', 'Kumquats', 'Lemon', 'Lemon Meyer', 'Limes', 'Lychee', 'Mandarine', 'Mango', 'Maracuja', 'Melon Piel de Sapo', 'Mulberry', 'Nectarine', 'Orange', 'Papaya', 'Passion Fruit', 'Peach', 'Peach Flat', 'Pear', 'Pear Abate', 'Pear Monster', 'Pear Williams', 'Pepino', 'Physalis', 'Physalis with Husk', 'Pineapple', 'Pineapple Mini', 'Pitahaya Red', 'Plum', 'Pomegranate', 'Quince', 'Rambutan', 'Raspberry', 'Salak', 'Strawberry', 'Strawberry Wedge', 'Tamarillo', 'Tangelo', 'Tomato 1', 'Tomato 2', 'Tomato 3', 'Tomato 4', 'Tomato Cherry Red', 'Tomato Maroon', 'Walnut']\n"
     ]
    }
   ],
   "source": [
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c9f521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98bd7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d16457c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(train_dataset, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d46f407a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 100, 100]) 0\n"
     ]
    }
   ],
   "source": [
    "img, label = dataset[1]\n",
    "print(img.shape, label)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feabad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image shape and default size being 224*224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb8c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size is given as 128 because the dataset is large and has large number of samples (Tweak made here corresponding to dataset in hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a00cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14f593e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4299b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 5000\n",
    "train_size = len(dataset) - valid_size\n",
    "train_ds, valid_ds = random_split(dataset, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a534e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55f44df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c411f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For visualisation if required ; batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c025487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68a16464",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90640cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aacfcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model as VGG16 architecture and printing the pretrained model with its architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b9c89f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4022e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = models.vgg16_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd466f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Characterisitics of the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ebe4738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "print(vgg.features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cca70da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout(p=0.5, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "print(vgg.classifier[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dec3d7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=4096, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(vgg.classifier[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a96842",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding last linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c7e7e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear(in_features=25088, out_features=4096, bias=True), ReLU(inplace=True), Dropout(p=0.5, inplace=False), Linear(in_features=4096, out_features=4096, bias=True), ReLU(inplace=True), Dropout(p=0.5, inplace=False), Linear(in_features=4096, out_features=81, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "final_in_features = vgg.classifier[6].in_features\n",
    "mod_classifier = list(vgg.classifier.children())[:-1]\n",
    "mod_classifier.extend([nn.Linear(final_in_features, num_classes)])\n",
    "print(mod_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a8cb1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=81, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg.classifier = nn.Sequential(*mod_classifier)\n",
    "print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efd1e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cb1c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba391e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader, model):\n",
    "    total, correct = 0, 0\n",
    "    for data in dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3906dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0df97ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631b8733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usage of SGD as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specified learning rate of 0.01(Tweak )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "424aeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = vgg.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.SGD(vgg.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33cd8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fbf600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining loss with respect to each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37110aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specified number of epochs as 4(Tweak made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training batch loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae0b7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0/391, Loss: 4.53\n",
      "Iteration: 100/391, Loss: 0.57\n",
      "Iteration: 200/391, Loss: 0.07\n"
     ]
    }
   ],
   "source": [
    "loss_epoch_arr = []\n",
    "max_epochs = 4\n",
    "\n",
    "n_iters = np.ceil(50000/batch_size)\n",
    "#Model is to train\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "         #Zero grads to cleaer graidents of optimized variables\n",
    "        opt.zero_grad()\n",
    "         #computing predicted outputs\n",
    "         #forward pass - passing input to model\n",
    "        outputs = vgg(inputs)\n",
    "        #calculating batch loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        del inputs, labels, outputs\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('Iteration: %d/%d, Loss: %0.2f' % (i, n_iters, loss.item()))\n",
    "        \n",
    "    loss_epoch_arr.append(loss.item())\n",
    "        \n",
    "    print('Epoch: %d/%d, Test acc: %0.2f, Train acc: %0.2f' % (\n",
    "        epoch, max_epochs, \n",
    "        evaluation(valid_dl, vgg), evaluation(train_dl, vgg)))\n",
    "    \n",
    "plt.plot(loss_epoch_arr)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
